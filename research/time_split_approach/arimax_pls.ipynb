{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57ebabe-0025-43f1-906a-28914ca96007",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smts\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from typing import Union\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2de1762-41df-4388-a200-80e2e9c48d68",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "def fit_arimax_model(order, endog, exog, d):\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            model = SARIMAX(endog, exog=exog, order=(order[0], d, order[1]), simple_differencing=False).fit(disp=False)\n",
    "            aic = model.aic\n",
    "            bic = model.bic\n",
    "            return [(order[0], d, order[1]), round(aic, 2), round(bic, 2)]\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def optimize_ARIMAX(endog: Union[pd.Series, list], exog: Union[pd.Series, list], order_list: list, d: int) -> pd.DataFrame:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        results = Parallel(n_jobs=-1)(delayed(fit_arimax_model)(order, endog, exog, d) for order in tqdm(order_list))\n",
    "    \n",
    "    results = [result for result in results if result is not None]\n",
    "\n",
    "    result_df = pd.DataFrame(results, columns=['(p, d, q)', 'AIC', 'BIC'])\n",
    "    result_df = result_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "    order_arimax = result_df['(p, d, q)'].iloc[0]    \n",
    "    \n",
    "    return result_df, order_arimax\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    non_zero_indices = np.where(y_true != 0)[0]\n",
    "    y_true_no_zeros = np.array(y_true)[non_zero_indices]\n",
    "    y_pred_no_zeros = np.array(y_pred)[non_zero_indices]\n",
    "    abs_perc_err = np.abs((y_true_no_zeros - y_pred_no_zeros) / y_true_no_zeros)\n",
    "    mape_value = np.mean(abs_perc_err) * 100\n",
    "    return mape_value\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def optimize_ncomp_pls(X, y, n_comp_range, ylabel, objective):\n",
    "    errors = []\n",
    "    xticks = np.arange(1, n_comp_range + 1)\n",
    "\n",
    "    for n_comp in xticks:\n",
    "        pls = PLSRegression(n_components=n_comp)\n",
    "        y_cv = cross_val_predict(pls, X, y, cv=10)\n",
    "        error = rmse(y, y_cv)\n",
    "        errors.append(error)\n",
    "\n",
    "    with plt.style.context('ggplot'):\n",
    "        plt.plot(xticks, np.array(errors), 'o-', color='blue', mfc='blue')\n",
    "        if objective == 'min':\n",
    "            idx = np.argmin(errors)\n",
    "        else:\n",
    "            idx = np.argmax(errors)\n",
    "        plt.plot(xticks[idx], np.array(errors)[idx], 'P', ms=10, mfc='red')\n",
    "\n",
    "        plt.xlabel('Number of PLS components')\n",
    "        plt.xticks = xticks\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title('PLS')\n",
    "        plt.grid(True, linestyle='dashed', color='gray')\n",
    "        plt.gca().set_facecolor('white')\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f42a4e85-80f5-43f3-be31-fd99734a2536",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data_sensors_rovere.csv')\n",
    "df = df.rename(columns={'group': 'group_id'})\n",
    "\n",
    "df_rovere = df[['reading_id', 'timestamp', 'sensor_id', 'value', 'description', 'group_id']]\n",
    "\n",
    "df_rovere['reading_id'] = df_rovere['reading_id'].astype(str)\n",
    "df_rovere['timestamp'] = pd.to_datetime(df_rovere['timestamp']).dt.floor('D').dt.date\n",
    "df_rovere['sensor_id'] = df_rovere['sensor_id'].astype(str)\n",
    "df_rovere['value'] = df_rovere['value'].astype(float)\n",
    "df_rovere['description'] = df_rovere['description'].astype(str)\n",
    "df_rovere['group_id'] = df_rovere['group_id'].astype(str)\n",
    "\n",
    "condition_30 = df_rovere['sensor_id'].isin(['72', '76', '73', '74', '61', '63', '67', '65'])\n",
    "condition_60 = df_rovere['sensor_id'].isin(['71', '69', '75', '70', '62', '64', '68', '66'])\n",
    "condition_irrigation = df_rovere['description'] == 'irrigation'\n",
    "\n",
    "df_rovere.loc[condition_30, 'description'] = 'Tensiometer 30'\n",
    "df_rovere.loc[condition_60, 'description'] = 'Tensiometer 60'\n",
    "df_rovere.loc[condition_irrigation, 'description'] = 'Irrigation'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b4cf0b90-3d82-4745-b9be-951495a73f8b",
   "metadata": {},
   "source": [
    "### Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc16869-425b-4108-872b-24f561be0bb0",
   "metadata": {},
   "source": [
    "df_group_1 = df_rovere[df_rovere['group_id'] == '1'].reset_index(drop=True)\n",
    "df_group_1 = df_group_1.groupby(['timestamp', 'description']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group_1.columns = ['timestamp', 'description', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot_1 = df_group_1.pivot(index='timestamp', columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot_1.columns.name = None\n",
    "df_pivot_1.columns = ['date', 'min_hum', 'min_temp', 'min_solar', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                      'max_hum', 'max_temp', 'max_solar', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                      'avg_hum', 'avg_temp', 'avg_solar', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                      'med_hum', 'med_temp', 'med_solar', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                      'sum_hum', 'sum_temp', 'sum_solar', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "\n",
    "df_pivot_1 = df_pivot_1.dropna().reset_index(drop=True)\n",
    "df = df_pivot_1\n",
    "\n",
    "\n",
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'avg_rain']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "col_drop_30 = ['min_tens60', 'max_tens60', 'avg_tens60', 'med_tens60', 'sum_tens60']\n",
    "df_30 = df.drop(columns=col_drop_30).dropna().reset_index(drop=True)\n",
    "\n",
    "col_drop_60 = ['min_tens30', 'max_tens30', 'avg_tens30', 'med_tens30', 'sum_tens30']\n",
    "df_60 = df.drop(columns=col_drop_60).dropna().reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "71aabb1c-7f66-4095-88dd-fa7e8dcd1fba",
   "metadata": {},
   "source": [
    "#### Sensor 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9fca92a-baf2-4762-a9ad-0234c13c4fb8",
   "metadata": {},
   "source": [
    "y = df_30['avg_tens30']\n",
    "X = df_30.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens30_lag1', 'avg_tens30_lag2', 'avg_tens30_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eda6c8e-3ff8-48ac-b982-189246bcc73f",
   "metadata": {},
   "source": [
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6785570-3489-4045-8ea0-20c41b960fc6",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=2)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e1e506-9313-4467-9ce3-4a17b0edc7ba",
   "metadata": {},
   "source": [
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e97c89a6-17c3-470c-9e9d-8d36bf9abb30",
   "metadata": {},
   "source": [
    "residuals_naive = y_test - naive_pred[-len(y_test):]\n",
    "residuals_ARIMAX = y_test - arimax_pred\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "combined_index = np.concatenate([y_train.index, y_test.index])\n",
    "combined_index_1 = np.concatenate([y_train.index, y_test[:-1].index])\n",
    "\n",
    "new_indices = np.arange(len(y_train), len(y_train) + len(y_test))\n",
    "arimax_pred_df = pd.DataFrame(arimax_pred, index=new_indices, columns=['ARIMAX Prediction'])\n",
    "\n",
    "ax.plot(combined_index, np.concatenate([y_train, y_test]), label='Original Series', color='blue')\n",
    "ax.plot(y_test, 'b-', label='Actual', color='black')\n",
    "\n",
    "ax.plot(naive_pred[-len(y_test):], 'r:', label='Naive Method', color='red')\n",
    "ax.scatter(combined_index[-len(y_test):], residuals_naive, color='orange', label='Residuals Naive', marker='o')\n",
    "\n",
    "ax.plot(arimax_pred_df.iloc[:-1], 'k--', label='ARIMAX', color='green')\n",
    "ax.scatter(combined_index[-len(y_test):-1], residuals_ARIMAX[:-1], color='purple', label='Residuals ARIMAX', marker='x')\n",
    "\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Avg Tens 30')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d649acc6-b603-491a-a574-c251ad3e5462",
   "metadata": {},
   "source": [
    "#### Sensor 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afaf6b23-775d-4b0f-a4da-4f3e7c6ce40a",
   "metadata": {},
   "source": [
    "y = df_60['avg_tens60']\n",
    "X = df_60.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens60_lag1', 'avg_tens60_lag2', 'avg_tens60_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c069ef0-4a63-4072-9845-c9682842b59c",
   "metadata": {},
   "source": [
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8013e5e-6a62-40e9-a170-9e5af8aea2be",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=6)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445ec007-54da-4b7a-ab63-4f4249d17a00",
   "metadata": {},
   "source": [
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61659336-99ce-4e06-897a-f74c140ef60a",
   "metadata": {},
   "source": [
    "residuals_naive = y_test - naive_pred[-len(y_test):]\n",
    "residuals_ARIMAX = y_test - arimax_pred\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "combined_index = np.concatenate([y_train.index, y_test.index])\n",
    "combined_index_1 = np.concatenate([y_train.index, y_test[:-1].index])\n",
    "\n",
    "new_indices = np.arange(len(y_train), len(y_train) + len(y_test))\n",
    "arimax_pred_df = pd.DataFrame(arimax_pred, index=new_indices, columns=['ARIMAX Prediction'])\n",
    "\n",
    "ax.plot(combined_index, np.concatenate([y_train, y_test]), label='Original Series', color='blue')\n",
    "ax.plot(y_test, 'b-', label='Actual', color='black')\n",
    "\n",
    "ax.plot(naive_pred[-len(y_test):], 'r:', label='Last Method', color='red')\n",
    "ax.scatter(combined_index[-len(y_test):], residuals_naive, color='orange', label='Residuals Naive', marker='o')\n",
    "\n",
    "ax.plot(arimax_pred_df.iloc[:-1], 'k--', label='ARIMAX', color='green')\n",
    "ax.scatter(combined_index[-len(y_test):-1], residuals_ARIMAX[:-1], color='purple', label='Residuals ARIMAX', marker='x')\n",
    "\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Avg Tens 60')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b9255905-b16b-4efa-96e8-3b9a11a9da52",
   "metadata": {},
   "source": [
    "### Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc48321d-19b1-4928-bfc0-7bd513843c42",
   "metadata": {},
   "source": [
    "df_group_2 = df_rovere[df_rovere['group_id'] == '2'].reset_index(drop=True)\n",
    "df_group_2 = df_group_2.groupby(['timestamp', 'description']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group_2.columns = ['timestamp', 'description', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot_2 = df_group_2.pivot(index='timestamp', columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot_2.columns.name = None\n",
    "df_pivot_2.columns = ['date', 'min_hum', 'min_temp', 'min_solar', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                      'max_hum', 'max_temp', 'max_solar', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                      'avg_hum', 'avg_temp', 'avg_solar', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                      'med_hum', 'med_temp', 'med_solar', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                      'sum_hum', 'sum_temp', 'sum_solar', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "\n",
    "df_pivot_2 = df_pivot_2.dropna().reset_index(drop=True)\n",
    "df = df_pivot_2\n",
    "\n",
    "\n",
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'avg_rain']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "col_drop_30 = ['min_tens60', 'max_tens60', 'avg_tens60', 'med_tens60', 'sum_tens60']\n",
    "df_30 = df.drop(columns=col_drop_30).dropna().reset_index(drop=True)\n",
    "\n",
    "col_drop_60 = ['min_tens30', 'max_tens30', 'avg_tens30', 'med_tens30', 'sum_tens30']\n",
    "df_60 = df.drop(columns=col_drop_60).dropna().reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1b41a9d6-2657-4a14-b0db-d46f5dfbbcc4",
   "metadata": {},
   "source": [
    "#### Sensor 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e37cb254-fa26-4f34-8aae-c6f110c60e02",
   "metadata": {},
   "source": [
    "y = df_30['avg_tens30']\n",
    "X = df_30.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens30_lag1', 'avg_tens30_lag2', 'avg_tens30_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc004112-027e-4b2d-8b4b-b55b98abb287",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=1)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "391903f6-f5f9-4e5a-b747-5eb7b6832713",
   "metadata": {},
   "source": [
    "#### Sensor 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d965b14e-4f74-4831-883e-28a349293c6a",
   "metadata": {},
   "source": [
    "y = df_60['avg_tens60']\n",
    "X = df_60.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens60_lag1', 'avg_tens60_lag2', 'avg_tens60_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7931fdd-24a8-426f-bacb-b40ce4f1f1b3",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=1)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ebd59ccf-a142-463e-9fc7-05dea26bea7f",
   "metadata": {},
   "source": [
    "### Group 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d9b9c6b-281d-4355-ba23-237e082dfc4d",
   "metadata": {},
   "source": [
    "df_group_3 = df_rovere[df_rovere['group_id'] == '3'].reset_index(drop=True)\n",
    "df_group_3 = df_group_3.groupby(['timestamp', 'description']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group_3.columns = ['timestamp', 'description', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot_3 = df_group_3.pivot(index='timestamp', columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot_3.columns.name = None\n",
    "df_pivot_3.columns = ['date', 'min_hum', 'min_temp', 'min_solar', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                      'max_hum', 'max_temp', 'max_solar', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                      'avg_hum', 'avg_temp', 'avg_solar', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                      'med_hum', 'med_temp', 'med_solar', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                      'sum_hum', 'sum_temp', 'sum_solar', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "\n",
    "df_pivot_3 = df_pivot_3.dropna().reset_index(drop=True)\n",
    "df = df_pivot_3\n",
    "\n",
    "\n",
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'avg_rain']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "col_drop_30 = ['min_tens60', 'max_tens60', 'avg_tens60', 'med_tens60', 'sum_tens60']\n",
    "df_30 = df.drop(columns=col_drop_30).dropna().reset_index(drop=True)\n",
    "\n",
    "col_drop_60 = ['min_tens30', 'max_tens30', 'avg_tens30', 'med_tens30', 'sum_tens30']\n",
    "df_60 = df.drop(columns=col_drop_60).dropna().reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "82571a76-8822-4627-9c49-5c156521dd8c",
   "metadata": {},
   "source": [
    "#### Sensor 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f89342c9-701a-4bee-b105-6ce2a2bdc7d6",
   "metadata": {},
   "source": [
    "y = df_30['avg_tens30']\n",
    "X = df_30.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens30_lag1', 'avg_tens30_lag2', 'avg_tens30_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe7dfd9-879f-4a66-bd33-9a21a855280c",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=2)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dc7d2512-5aaa-47f9-a47c-6e1db9b1595f",
   "metadata": {},
   "source": [
    "#### Sensor 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aa728f3-410f-49df-abdc-f676878c46a3",
   "metadata": {},
   "source": [
    "y = df_60['avg_tens60']\n",
    "X = df_60.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens60_lag1', 'avg_tens60_lag2', 'avg_tens60_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8394e51a-d07a-4690-b02c-ec1dacaf1df5",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=2)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "254f7af5-b38b-407c-adba-b6124c85785f",
   "metadata": {},
   "source": [
    "### Group 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a32549c-48b8-4702-abd3-e86da5ff02d5",
   "metadata": {},
   "source": [
    "df_group_4 = df_rovere[df_rovere['group_id'] == '4'].reset_index(drop=True)\n",
    "df_group_4 = df_group_4.groupby(['timestamp', 'description']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group_4.columns = ['timestamp', 'description', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot_4 = df_group_4.pivot(index='timestamp', columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot_4.columns.name = None\n",
    "df_pivot_4.columns = ['date', 'min_hum', 'min_temp', 'min_solar', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                      'max_hum', 'max_temp', 'max_solar', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                      'avg_hum', 'avg_temp', 'avg_solar', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                      'med_hum', 'med_temp', 'med_solar', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                      'sum_hum', 'sum_temp', 'sum_solar', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "\n",
    "df_pivot_4 = df_pivot_4.dropna().reset_index(drop=True)\n",
    "df = df_pivot_4\n",
    "\n",
    "\n",
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'avg_rain']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "col_drop_30 = ['min_tens60', 'max_tens60', 'avg_tens60', 'med_tens60', 'sum_tens60']\n",
    "df_30 = df.drop(columns=col_drop_30).dropna().reset_index(drop=True)\n",
    "\n",
    "col_drop_60 = ['min_tens30', 'max_tens30', 'avg_tens30', 'med_tens30', 'sum_tens30']\n",
    "df_60 = df.drop(columns=col_drop_60).dropna().reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9aec5f19-5ea2-46fc-ae62-ae88dd3fbde0",
   "metadata": {},
   "source": [
    "#### Sensor 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb969a32-971a-4649-90d2-8be3ad60fbc6",
   "metadata": {},
   "source": [
    "y = df_30['avg_tens30']\n",
    "X = df_30.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens30_lag1', 'avg_tens30_lag2', 'avg_tens30_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "233a370e-5b87-40f8-a20d-711549189f14",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=14)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "321f9b71-d042-4fa9-acf9-bc357536814b",
   "metadata": {},
   "source": [
    "#### Sensor 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d95e9e1-fe63-490a-a2ae-c979f3f53311",
   "metadata": {},
   "source": [
    "y = df_60['avg_tens60']\n",
    "X = df_60.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens60_lag1', 'avg_tens60_lag2', 'avg_tens60_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbb32bbb-946f-4ed4-96d2-10ede4cb0f97",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=5)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0df2c1ab-88aa-46f2-8d24-17d72d3b1bc8",
   "metadata": {},
   "source": [
    "### Group 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb4860f8-bd9f-4f87-8e21-7f1b8b6be613",
   "metadata": {},
   "source": [
    "df_group_5 = df_rovere[df_rovere['group_id'] == '5'].reset_index(drop=True)\n",
    "df_group_5 = df_group_5.groupby(['timestamp', 'description']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group_5.columns = ['timestamp', 'description', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot_5 = df_group_5.pivot(index='timestamp', columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot_5.columns.name = None\n",
    "df_pivot_5.columns = ['date', 'min_hum', 'min_temp', 'min_solar', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                      'max_hum', 'max_temp', 'max_solar', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                      'avg_hum', 'avg_temp', 'avg_solar', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                      'med_hum', 'med_temp', 'med_solar', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                      'sum_hum', 'sum_temp', 'sum_solar', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "df_pivot_5 = df_pivot_5.dropna().reset_index(drop=True)\n",
    "\n",
    "df = df_pivot_5\n",
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'avg_rain']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "col_drop_30 = ['min_tens60', 'max_tens60', 'avg_tens60', 'med_tens60', 'sum_tens60']\n",
    "df_30 = df.drop(columns=col_drop_30).dropna().reset_index(drop=True)\n",
    "\n",
    "col_drop_60 = ['min_tens30', 'max_tens30', 'avg_tens30', 'med_tens30', 'sum_tens60']\n",
    "df_60 = df.drop(columns=col_drop_60).dropna().reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ecf7343d-af8a-4a44-86b8-f6d12867052a",
   "metadata": {},
   "source": [
    "#### Sensor 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e12ae217-3040-4ef2-a2f3-7db07a607082",
   "metadata": {},
   "source": [
    "y = df_30['avg_tens30']\n",
    "X = df_30.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens30_lag1', 'avg_tens30_lag2', 'avg_tens30_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bebc4b4-6434-4382-b167-96f8c2982181",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=2)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "16715279-5762-409c-9aaf-da52819baae9",
   "metadata": {},
   "source": [
    "#### Sensor 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1891126f-ffda-4e72-bac5-a05546a180a2",
   "metadata": {},
   "source": [
    "y = df_60['avg_tens60']\n",
    "X = df_60.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens60_lag1', 'avg_tens60_lag2', 'avg_tens60_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ab6d68e-6b03-4169-aa66-33ed70e1b456",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=2)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "744a814b-9951-40ee-ae8e-28df19e8809a",
   "metadata": {},
   "source": [
    "### Group 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55d0df13-1c20-433a-ba4e-0080417ad926",
   "metadata": {},
   "source": [
    "df_group_6 = df_rovere[df_rovere['group_id'] == '6'].reset_index(drop=True)\n",
    "df_group_6 = df_group_6.groupby(['timestamp', 'description']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group_6.columns = ['timestamp', 'description', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot_6 = df_group_6.pivot(index='timestamp', columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot_6.columns.name = None\n",
    "df_pivot_6.columns = ['date', 'min_hum', 'min_temp', 'min_solar', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                      'max_hum', 'max_temp', 'max_solar', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                      'avg_hum', 'avg_temp', 'avg_solar', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                      'med_hum', 'med_temp', 'med_solar', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                      'sum_hum', 'sum_temp', 'sum_solar', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "df_pivot_6 = df_pivot_6.dropna().reset_index(drop=True)\n",
    "\n",
    "df = df_pivot_6\n",
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'avg_rain']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "col_drop_30 = ['min_tens60', 'max_tens60', 'avg_tens60', 'med_tens60', 'sum_tens60']\n",
    "df_30 = df.drop(columns=col_drop_30).dropna().reset_index(drop=True)\n",
    "\n",
    "col_drop_60 = ['min_tens30', 'max_tens30', 'avg_tens30', 'med_tens30', 'sum_tens60']\n",
    "df_60 = df.drop(columns=col_drop_60).dropna().reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d461f760-cdaa-4081-ab29-08fa5f07d016",
   "metadata": {},
   "source": [
    "#### Sensor 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a5c2dad-7593-46be-a8fc-60695cde341a",
   "metadata": {},
   "source": [
    "y = df_30['avg_tens30']\n",
    "X = df_30.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens30_lag1', 'avg_tens30_lag2', 'avg_tens30_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e7aae2a-01e7-4f61-a163-11b60f12d579",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=15)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ffceba77-401a-437d-be53-05eaa04ec372",
   "metadata": {},
   "source": [
    "#### Sensor 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21c72e2b-9f3c-4613-ab9d-552fa7608d9c",
   "metadata": {},
   "source": [
    "y = df_60['avg_tens60']\n",
    "X = df_60.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens60_lag1', 'avg_tens60_lag2', 'avg_tens60_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74ff8d91-4208-426c-aced-0ef27a73b516",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=11)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ab3d9cca-ecb8-4859-a9d7-2870daa12858",
   "metadata": {},
   "source": [
    "### Group 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9dc62490-e7de-41a6-ba21-682741639bf7",
   "metadata": {},
   "source": [
    "df_group_7 = df_rovere[df_rovere['group_id'] == '7'].reset_index(drop=True)\n",
    "df_group_7 = df_group_7.groupby(['timestamp', 'description']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group_7.columns = ['timestamp', 'description', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot_7 = df_group_7.pivot(index='timestamp', columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot_7.columns.name = None\n",
    "df_pivot_7.columns = ['date', 'min_hum', 'min_temp', 'min_solar', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                      'max_hum', 'max_temp', 'max_solar', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                      'avg_hum', 'avg_temp', 'avg_solar', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                      'med_hum', 'med_temp', 'med_solar', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                      'sum_hum', 'sum_temp', 'sum_solar', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "df_pivot_7 = df_pivot_7.dropna().reset_index(drop=True)\n",
    "\n",
    "df = df_pivot_7\n",
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'avg_rain']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "col_drop_30 = ['min_tens60', 'max_tens60', 'avg_tens60', 'med_tens60', 'sum_tens60']\n",
    "df_30 = df.drop(columns=col_drop_30).dropna().reset_index(drop=True)\n",
    "\n",
    "col_drop_60 = ['min_tens30', 'max_tens30', 'avg_tens30', 'med_tens30', 'sum_tens30']\n",
    "df_60 = df.drop(columns=col_drop_60).dropna().reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a10bd1-81ad-42c2-8a40-888617bfb399",
   "metadata": {},
   "source": [
    "#### Sensor 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76aacd6b-9a3a-40fa-b0a2-1c4ae50fe31d",
   "metadata": {},
   "source": [
    "y = df_30['avg_tens30']\n",
    "X = df_30.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens30_lag1', 'avg_tens30_lag2', 'avg_tens30_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dbbed0f-adf7-4780-85b6-8d3d798e4d2a",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=13)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a20cdb0e-805b-4cfd-8e56-dcf582743355",
   "metadata": {},
   "source": [
    "#### Sensor 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86d197b1-c556-4700-a50f-e322c9df9720",
   "metadata": {},
   "source": [
    "y = df_60['avg_tens60']\n",
    "X = df_60.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens60_lag1', 'avg_tens60_lag2', 'avg_tens60_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d46c7f1-220c-4475-ae53-04c03b2c0cee",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=1)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "808d5bb6-50d1-4f68-b836-0e8ee13cf92c",
   "metadata": {},
   "source": [
    "### Group 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4cdd6ad-36b9-4386-a93f-024d5cc0b849",
   "metadata": {},
   "source": [
    "df_group_8 = df_rovere[df_rovere['group_id'] == '8'].reset_index(drop=True)\n",
    "df_group_8 = df_group_8.groupby(['timestamp', 'description']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group_8.columns = ['timestamp', 'description', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot_8 = df_group_8.pivot(index='timestamp', columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot_8.columns.name = None\n",
    "df_pivot_8.columns = ['date', 'min_hum', 'min_temp', 'min_solar', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                      'max_hum', 'max_temp', 'max_solar', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                      'avg_hum', 'avg_temp', 'avg_solar', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                      'med_hum', 'med_temp', 'med_solar', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                      'sum_hum', 'sum_temp', 'sum_solar', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "df_pivot_8 = df_pivot_8.dropna().reset_index(drop=True)\n",
    "\n",
    "df = df_pivot_8\n",
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'avg_rain']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "col_drop_30 = ['min_tens60', 'max_tens60', 'avg_tens60', 'med_tens60', 'sum_tens60']\n",
    "df_30 = df.drop(columns=col_drop_30).dropna().reset_index(drop=True)\n",
    "\n",
    "col_drop_60 = ['min_tens30', 'max_tens30', 'avg_tens30', 'med_tens30', 'sum_tens30']\n",
    "df_60 = df.drop(columns=col_drop_60).dropna().reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3b16db-a427-470e-a4c1-d90844e62156",
   "metadata": {},
   "source": [
    "#### Sensor 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a97c90a-74fd-448a-bb95-91f28edb6569",
   "metadata": {},
   "source": [
    "y = df_30['avg_tens30']\n",
    "X = df_30.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens30_lag1', 'avg_tens30_lag2', 'avg_tens30_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78d0681e-b616-42df-a6ef-9539637fdab4",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=2)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a0defe72-bb55-4bba-aa49-ff9b78af0b3c",
   "metadata": {},
   "source": [
    "#### Sensor 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b40cc40-6cd7-4ac7-9dd7-ab8585c877ce",
   "metadata": {},
   "source": [
    "y = df_60['avg_tens60']\n",
    "X = df_60.drop(['date'], axis=1)\n",
    "\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "columns_to_drop = ['avg_tens60_lag1', 'avg_tens60_lag2', 'avg_tens60_lag3']\n",
    "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "y = y.iloc[3:].reset_index(drop=True)\n",
    "X = X.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)\n",
    "\n",
    "optimize_ncomp_pls(X_train, y_train, 30, 'RMSE', 'min')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "231543b5-89fa-4f09-b65a-6746472d4778",
   "metadata": {},
   "source": [
    "naive_pred = pd.concat([y_train.shift(1).fillna(y_train.iloc[-1])[1:], y_test.shift(1).fillna(y_train.iloc[-1])])\n",
    "\n",
    "pls_model = PLSRegression(n_components=8)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8'])\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8'])\n",
    "\n",
    "linear_reg_model = sm.OLS(y_train, sm.add_constant(X_train_pls)).fit()\n",
    "\n",
    "train_linear_pred = linear_reg_model.predict(sm.add_constant(X_train_pls))\n",
    "linear_pred = linear_reg_model.predict(sm.add_constant(X_test_pls))\n",
    "\n",
    "\n",
    "ps = range(0, 11, 1)\n",
    "qs = range(0, 11, 1)\n",
    "d = 1\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "\n",
    "\n",
    "result_df, order_arimax = optimize_ARIMAX(y_train, X_train_pls, order_list, d)\n",
    "model = SARIMAX(endog=y_train, exog=X_train_pls, order=order_arimax)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "res_train_arimax = results.resid\n",
    "train_arimax_pred = y_train - res_train_arimax\n",
    "\n",
    "\n",
    "arimax_pred = []\n",
    "y_new_train = y_train.copy()\n",
    "X_new_train = X_train_pls.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    next_exog = X_test_pls.iloc[i, :]\n",
    "    \n",
    "    forecast = results.get_forecast(steps=1, exog=next_exog)\n",
    "    forecast_value = forecast.predicted_mean.values[0]\n",
    "    arimax_pred.append(forecast_value)\n",
    "\n",
    "    y_new_train = pd.concat([y_new_train, pd.Series([y_test.iloc[i]], index=[y_new_train.index[-1] + 1])])\n",
    "    X_new_train = pd.concat([X_new_train, next_exog.to_frame().transpose()], ignore_index=True)\n",
    "    \n",
    "    model = SARIMAX(endog=y_new_train, exog=X_new_train, order=order_arimax)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "\n",
    "mape_naive = round(mape(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "mae_naive = round(mae(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "rmse_naive = round(rmse(pd.concat([y_train[1:], y_test]), naive_pred), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_arimax = round(mape(y_train, train_arimax_pred), 3)\n",
    "mae_train_arimax = round(mae(y_train, train_arimax_pred), 3)\n",
    "rmse_train_arimax = round(rmse(y_train, train_arimax_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_ARIMAX = round(mape(y_test, arimax_pred), 3)\n",
    "mae_ARIMAX = round(mae(y_test, arimax_pred), 3)\n",
    "rmse_ARIMAX = round(rmse(y_test, arimax_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'Naive Method', 'LM Train', 'ARIMAX Train', 'LM Test', 'ARIMAX Test'],\n",
    "    ['MAPE', mape_naive, mape_train_linear, mape_train_arimax, mape_linear, mape_ARIMAX],\n",
    "    ['MAE', mae_naive, mae_train_linear, mae_train_arimax, mae_linear, mae_ARIMAX],\n",
    "    ['RMSE', rmse_naive, rmse_train_linear, rmse_train_arimax, rmse_linear, rmse_ARIMAX]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
