{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8f88d5-a11b-4108-adec-d0e7b0cee783",
   "metadata": {},
   "source": [
    "# Panel Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28715242-2d52-435e-8012-04b2689b5512",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7461119-1b64-42ac-8150-a1fd16a2fa81",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "#from linearmodels.panel import PanelOLS, RandomEffects\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d57c5aa-ee77-4cac-90ce-93a5aa94f4ff",
   "metadata": {},
   "source": [
    "def calculate_aic(y_true, y_pred, num_features):\n",
    "    resid = y_true - y_pred\n",
    "    sse = np.sum(resid ** 2)\n",
    "    aic = len(y_true) * np.log(sse / len(y_true)) + 2 * num_features\n",
    "    return aic\n",
    "\n",
    "\n",
    "def calculate_bic(y_true, y_pred, num_features):\n",
    "    resid = y_true - y_pred\n",
    "    sse = np.sum(resid ** 2)\n",
    "    n = len(y_true)\n",
    "    bic = n * np.log(sse / n) + num_features * np.log(n)\n",
    "    return bic\n",
    "\n",
    "\n",
    "def forward_step(X_train, y_train, selected_features, remaining_features, criterion_func):\n",
    "    best_criterion = np.inf\n",
    "    best_feature = None\n",
    "    \n",
    "    for feature in remaining_features:\n",
    "        temp_features = selected_features + [feature]\n",
    "        temp_model = sm.OLS(y_train, sm.add_constant(X_train[temp_features])).fit()\n",
    "        temp_criterion = criterion_func(y_train, temp_model.predict(sm.add_constant(X_train[temp_features])), len(temp_model.params))\n",
    "        \n",
    "        if temp_criterion < best_criterion:\n",
    "            best_criterion = temp_criterion\n",
    "            best_feature = feature\n",
    "    \n",
    "    return best_criterion, best_feature\n",
    "\n",
    "def backward_step(X_train, y_train, selected_features, criterion_func):\n",
    "    best_criterion = np.inf\n",
    "    best_feature = None\n",
    "    \n",
    "    for feature in selected_features:\n",
    "        temp_features = selected_features.copy()\n",
    "        temp_features.remove(feature)\n",
    "        temp_model = sm.OLS(y_train, sm.add_constant(X_train[temp_features])).fit()\n",
    "        temp_criterion = criterion_func(y_train, temp_model.predict(sm.add_constant(X_train[temp_features])), len(temp_model.params))\n",
    "        \n",
    "        if temp_criterion < best_criterion:\n",
    "            best_criterion = temp_criterion\n",
    "            best_feature = feature\n",
    "    \n",
    "    return best_criterion, best_feature\n",
    "\n",
    "def stepwise_bidirectional_selection(X_train, y_train, method='aic'):\n",
    "    features = list(X_train.columns)\n",
    "    selected_features = []\n",
    "    best_criterion = np.inf\n",
    "    \n",
    "    while len(features) > 0:\n",
    "        if method == 'aic':\n",
    "            forward_criterion, forward_feature = forward_step(X_train, y_train, selected_features, features, calculate_aic)\n",
    "            backward_criterion, backward_feature = backward_step(X_train, y_train, selected_features, calculate_aic)\n",
    "        elif method == 'bic':\n",
    "            forward_criterion, forward_feature = forward_step(X_train, y_train, selected_features, features, calculate_bic)\n",
    "            backward_criterion, backward_feature = backward_step(X_train, y_train, selected_features, calculate_bic)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid criterion_func. Use 'aic' or 'bic'.\")\n",
    "        \n",
    "        if forward_criterion < backward_criterion and forward_criterion < best_criterion:\n",
    "            selected_features.append(forward_feature)\n",
    "            best_criterion = forward_criterion\n",
    "        elif backward_criterion < forward_criterion and backward_criterion < best_criterion:\n",
    "            selected_features.remove(backward_feature)\n",
    "            best_criterion = backward_criterion\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    non_zero_indices = np.where(y_true != 0)[0]\n",
    "    y_true_no_zeros = np.array(y_true)[non_zero_indices]\n",
    "    y_pred_no_zeros = np.array(y_pred)[non_zero_indices]\n",
    "\n",
    "    absolute_percentage_errors = np.abs((y_true_no_zeros - y_pred_no_zeros) / y_true_no_zeros)\n",
    "    mape_value = np.mean(absolute_percentage_errors) * 100\n",
    "    return mape_value\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc8cb143-a4b2-4d26-a7fb-ac3a4c6b26f9",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data_sensors_rovere.csv')\n",
    "df = df.rename(columns={'group': 'group_id'})\n",
    "\n",
    "df_rovere = df[['reading_id', 'timestamp', 'sensor_id', 'value', 'description', 'group_id']]\n",
    "\n",
    "df_rovere['reading_id'] = df_rovere['reading_id'].astype(str)\n",
    "df_rovere['timestamp'] = pd.to_datetime(df_rovere['timestamp']).dt.floor('D').dt.date\n",
    "df_rovere['sensor_id'] = df_rovere['sensor_id'].astype(str)\n",
    "df_rovere['value'] = df_rovere['value'].astype(float)\n",
    "df_rovere['description'] = df_rovere['description'].astype(str)\n",
    "df_rovere['group_id'] = df_rovere['group_id'].astype(str)\n",
    "\n",
    "condition_30 = df_rovere['sensor_id'].isin(['72', '76', '73', '74', '61', '63', '67', '65'])\n",
    "condition_60 = df_rovere['sensor_id'].isin(['71', '69', '75', '70', '62', '64', '68', '66'])\n",
    "condition_irrigation = df_rovere['description'] == 'irrigation'\n",
    "\n",
    "df_rovere.loc[condition_30, 'description'] = 'Tensiometer 30'\n",
    "df_rovere.loc[condition_60, 'description'] = 'Tensiometer 60'\n",
    "df_rovere.loc[condition_irrigation, 'description'] = 'Irrigation'\n",
    "\n",
    "print('Shape:', df_rovere.shape)\n",
    "print('Types:\\n', df_rovere.dtypes)\n",
    "df_rovere.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcbbcf5e-5864-492e-a67c-ecbdd5b70750",
   "metadata": {},
   "source": [
    "condition_not_in_list = ~df_rovere['sensor_id'].isin(['72', '76', '73', '74', '61', '63', '67', '65', '71', '69', '75', '70', '62', '64', '68', '66'])\n",
    "df_to_duplicate = df_rovere[condition_not_in_list]\n",
    "df_to_duplicate['group_id_1'] = df_to_duplicate['group_id'] + '_1'\n",
    "\n",
    "df_rovere = pd.concat([df_rovere, df_to_duplicate], ignore_index=True)\n",
    "df_rovere.sort_values(by=['group_id', 'timestamp'], inplace=True)\n",
    "df_rovere.reset_index(drop=True, inplace=True)\n",
    "\n",
    "condition_group_id_1 = df_rovere['group_id_1'].notnull()\n",
    "df_rovere.loc[condition_group_id_1, 'group_id'] = df_rovere.loc[condition_group_id_1, 'group_id_1']\n",
    "df_rovere.drop(columns=['group_id_1'], inplace=True)\n",
    "\n",
    "condition_update_group_id = df_rovere['sensor_id'].isin(['71', '69', '75', '70', '62', '64', '68', '66'])\n",
    "df_rovere.loc[condition_update_group_id, 'group_id'] = df_rovere.loc[condition_update_group_id, 'group_id'] + '_1'\n",
    "\n",
    "\n",
    "df_group = df_rovere.groupby(['timestamp', 'description', 'sensor_id', 'group_id']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group.columns = ['timestamp', 'description', 'sensor_id', 'group_id', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot = df_group.pivot(index=['timestamp', 'group_id'], columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot.columns.name = None\n",
    "df_pivot.columns = ['date', 'group_id', 'min_hum', 'min_temp', 'min_solar', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                    'max_hum', 'max_temp', 'max_solar', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                    'avg_hum', 'avg_temp', 'avg_solar', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                    'med_hum', 'med_temp', 'med_solar', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                    'sum_hum', 'sum_temp', 'sum_solar', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "\n",
    "df_pivot['min_tens'] = df_pivot['min_tens30'].combine_first(df_pivot['min_tens60'])\n",
    "df_pivot.drop(columns=['min_tens30', 'min_tens60'], inplace=True)\n",
    "\n",
    "\n",
    "df_pivot['max_tens'] = df_pivot['max_tens30'].combine_first(df_pivot['max_tens60'])\n",
    "df_pivot.drop(columns=['max_tens30', 'max_tens60'], inplace=True)\n",
    "\n",
    "\n",
    "df_pivot['avg_tens'] = df_pivot['avg_tens30'].combine_first(df_pivot['avg_tens60'])\n",
    "df_pivot.drop(columns=['avg_tens30', 'avg_tens60'], inplace=True)\n",
    "\n",
    "\n",
    "df_pivot['med_tens'] = df_pivot['med_tens30'].combine_first(df_pivot['med_tens60'])\n",
    "df_pivot.drop(columns=['med_tens30', 'med_tens60'], inplace=True)\n",
    "\n",
    "\n",
    "df_pivot['sum_tens'] = df_pivot['sum_tens30'].combine_first(df_pivot['sum_tens60'])\n",
    "df_pivot.drop(columns=['sum_tens30', 'sum_tens60'], inplace=True)\n",
    "\n",
    "df_pivot = df_pivot.dropna().reset_index(drop=True)\n",
    "\n",
    "df = df_pivot\n",
    "\n",
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'avg_rain']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "group_id_mapping = {\n",
    "    '1': '72',\n",
    "    '2': '76',\n",
    "    '3': '73',\n",
    "    '4': '74',\n",
    "    '5': '61',\n",
    "    '6': '63',\n",
    "    '7': '67',\n",
    "    '8': '65',\n",
    "    '1_1': '71',\n",
    "    '2_1': '69',\n",
    "    '3_1': '75',\n",
    "    '4_1': '70',\n",
    "    '5_1': '62',\n",
    "    '6_1': '64',\n",
    "    '7_1': '68',\n",
    "    '8_1': '66'\n",
    "}\n",
    "\n",
    "df['group_id'] = df['group_id'].replace(group_id_mapping)\n",
    "df = df.rename(columns={'group_id': 'sensor_id'})\n",
    "df = df[['sensor_id', 'date', 'avg_tens'] + [col for col in df.columns if col not in ['sensor_id', 'date', 'avg_tens']]]\n",
    "df = df.sort_values(by=['sensor_id', 'date']).reset_index(drop=True)\n",
    "\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2727a099-7c8b-4d1b-a400-9db52bd8503e",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c670929e-65e6-4f72-b683-b9c62e519e4c",
   "metadata": {},
   "source": [
    "ids = df['sensor_id']\n",
    "dates = df['date']\n",
    "X = df.drop(columns=['date', 'sensor_id'])\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "X['id'] = ids\n",
    "X['date'] = dates\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "X = X[~X['date'].isin(dates_to_remove)]\n",
    "X = X.sort_values(by=['date', 'id'])\n",
    "X = X.drop(columns=['id', 'date']).dropna().reset_index(drop=True)\n",
    "\n",
    "y = df[['avg_tens', 'date', 'sensor_id']]\n",
    "y = y[~y['date'].isin(dates_to_remove)]\n",
    "y = y.sort_values(by=['date', 'sensor_id'])\n",
    "y = y.drop(columns=['sensor_id', 'date']).dropna().reset_index(drop=True)\n",
    "y = y.squeeze()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "232fdb14-ebac-4cc3-893b-92c1cea841de",
   "metadata": {},
   "source": [
    "all_features_model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "all_features_predictions = all_features_model.predict(sm.add_constant(X_train))\n",
    "all_features_predictions_test = all_features_model.predict(sm.add_constant(X_test))\n",
    "\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "final_model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "\n",
    "train_linear_pred = final_model.predict(sm.add_constant(X_train[selected_features]))\n",
    "linear_pred = final_model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "print(f'Number of Selected Features: {len(selected_features)}')\n",
    "print(\"Selected Features:\")\n",
    "for feature in selected_features:\n",
    "    print(f\" - {feature}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "703991df-a88d-4bac-b3bf-32770ef2df0a",
   "metadata": {},
   "source": [
    "ids = df['sensor_id']\n",
    "dates = df['date']\n",
    "X = df.drop(columns=['date', 'sensor_id'])\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "X['id'] = ids\n",
    "X['date'] = dates\n",
    "\n",
    "dummies = pd.get_dummies(X['id'], drop_first=True).astype(int)\n",
    "dummy_features = dummies.columns.tolist()\n",
    "X = X.join(dummies)\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "X = X[~X['date'].isin(dates_to_remove)].dropna().reset_index(drop=True)\n",
    "X = X.sort_values(by=['date', 'id']).dropna().reset_index(drop=True)\n",
    "X = X.drop(columns=['id', 'date'])\n",
    "\n",
    "y = df[['avg_tens', 'date', 'sensor_id']]\n",
    "y = y[~y['date'].isin(dates_to_remove)]\n",
    "y = y.sort_values(by=['date', 'sensor_id'])\n",
    "y = y.drop(columns=['sensor_id', 'date']).dropna().reset_index(drop=True)\n",
    "y = y.squeeze()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7be3fa7-8dc9-443b-920b-3b6b98b3822d",
   "metadata": {},
   "source": [
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, X_train[selected_features]).fit()\n",
    "\n",
    "train_pool_pred = model.predict(X_train[selected_features])\n",
    "pool_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "\n",
    "print(f'Number of Selected Features: {len(selected_features)}')\n",
    "print(\"Selected Features:\")\n",
    "for feature in selected_features:\n",
    "    print(f\" - {feature}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f22af91-c94f-4cb2-939c-0fddbd7d9868",
   "metadata": {},
   "source": [
    "print(model.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23816a02-928e-44fb-a180-e969d2ab7a26",
   "metadata": {},
   "source": [
    "ids = df['sensor_id']\n",
    "dates = df['date']\n",
    "X = df.drop(columns=['date', 'sensor_id'])\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "X['id'] = ids\n",
    "X['date'] = dates\n",
    "\n",
    "dummies = pd.get_dummies(X['id'], drop_first=True).astype(int)\n",
    "dummy_features = dummies.columns.tolist()\n",
    "X = X.join(dummies)\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "X = X[~X['date'].isin(dates_to_remove)].dropna().reset_index(drop=True)\n",
    "X = X.sort_values(by=['date', 'id']).dropna().reset_index(drop=True)\n",
    "ids_sorted = X['id']\n",
    "dates_sorted = X['date']\n",
    "X = X.drop(columns=['id', 'date'])\n",
    "\n",
    "y = df[['avg_tens', 'date', 'sensor_id']]\n",
    "y = y[~y['date'].isin(dates_to_remove)]\n",
    "y = y.sort_values(by=['date', 'sensor_id'])\n",
    "y = y.drop(columns=['sensor_id', 'date']).dropna().reset_index(drop=True)\n",
    "y = y.squeeze()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29878, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "608c5214-1099-4ec2-8049-649446ed80fe",
   "metadata": {},
   "source": [
    "X_train_no_dummy = X_train.drop(dummy_features, axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcb6b70a-dc85-4de4-89f7-c9b4575f881b",
   "metadata": {},
   "source": [
    "X_train_ids = pd.concat([ids_sorted[:1840], X_train_no_dummy], axis=1)\n",
    "y_train_ids = pd.concat([ids_sorted[:1840], y_train], axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "619831aa-6948-4aef-badb-b4f31895dbaa",
   "metadata": {},
   "source": [
    "y_train_ids"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d5bb7fb-b94d-464d-986a-a5c033155555",
   "metadata": {},
   "source": [
    "X_train.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07575b35-b056-4139-b821-b2fffeee3c42",
   "metadata": {},
   "source": [
    "sensor_names = ['72', '76', '73', '74', '61', '63', '67', '65', '71', '69', '75', '70', '62', '64', '68', '66']\n",
    "n = len(sensor_names)\n",
    "T = X_train_no_dummy.shape[0] / n\n",
    "N=n*T\n",
    "k = X_train_no_dummy.shape[1] + 1\n",
    "k"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f39db8e6-353a-4fef-8d14-62643034e144",
   "metadata": {},
   "source": [
    "X_train"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2981897-0ee9-4865-9cdc-b60c7d4fa346",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "lm_model = sm.OLS(y_train, X_train_no_dummy).fit()\n",
    "lm_residuals = lm_model.resid\n",
    "\n",
    "sigma2_lm = lm_model.ssr/(n*T-(k+1))\n",
    "print('sigma2_pooled = ' + str(sigma2_lm))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bf6d3a3-0658-495a-b891-41c7fd17225c",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "fe_model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "sigma2_epsilon = fe_model.ssr/(n*T-(n+k+1))\n",
    "print('sigma2_epsilon = ' + str(sigma2_epsilon))\n",
    "\n",
    "sigma2_u = sigma2_lm - sigma2_epsilon\n",
    "print('sigma2_u = ' + str(sigma2_u))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a8153bb-8e9d-4747-a4b9-520efc9d2622",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "X_group_means = X_train_ids.groupby('id').mean()\n",
    "X_group_means"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fc61f61-b610-4c1e-b7f4-6ca4321e8f0d",
   "metadata": {},
   "source": [
    "y_group_means = y_train_ids.groupby('id').mean()\n",
    "y_group_means"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d949d7c6-ed5a-4886-922a-d9c2f132efc0",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "\n",
    "theta = 1 - math.sqrt(sigma2_epsilon/(sigma2_epsilon + T*sigma2_u))\n",
    "print('theta = ' + str(theta))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de86c7e5-8d3d-4b11-9a62-d597ba46e3b2",
   "metadata": {},
   "source": [
    "# sigma2_u / (sigma2_u + sigma2_epsilon)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2bbb107-8183-4983-9047-5a8f43c3d0e3",
   "metadata": {},
   "source": [
    "mape_train_linear_all = round(mape(y_train, all_features_predictions), 3)\n",
    "mae_train_linear_all = round(mae(y_train, all_features_predictions), 3)\n",
    "rmse_train_linear_all = round(rmse(y_train, all_features_predictions), 3)\n",
    "\n",
    "mape_train_linear = round(mape(y_train, train_linear_pred), 3)\n",
    "mae_train_linear = round(mae(y_train, train_linear_pred), 3)\n",
    "rmse_train_linear = round(rmse(y_train, train_linear_pred), 3)\n",
    "\n",
    "mape_train_pool = round(mape(y_train, train_pool_pred), 3)\n",
    "mae_train_pool = round(mae(y_train, train_pool_pred), 3)\n",
    "rmse_train_pool = round(rmse(y_train, train_pool_pred), 3)\n",
    "\n",
    "\n",
    "mape_linear_all = round(mape(y_test, all_features_predictions_test), 3)\n",
    "mae_linear_all = round(mae(y_test, all_features_predictions_test), 3)\n",
    "rmse_linear_all = round(rmse(y_test, all_features_predictions_test), 3)\n",
    "\n",
    "mape_linear = round(mape(y_test, linear_pred), 3)\n",
    "mae_linear = round(mae(y_test, linear_pred), 3)\n",
    "rmse_linear = round(rmse(y_test, linear_pred), 3)\n",
    "\n",
    "mape_pool = round(mape(y_test, pool_pred), 3)\n",
    "mae_pool = round(mae(y_test, pool_pred), 3)\n",
    "rmse_pool = round(rmse(y_test, pool_pred), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'LM Train ALL', 'LM Train', 'Pool Train', 'LM Test ALL', 'LM Test', 'Pool Test'],\n",
    "    ['MAPE', mape_train_linear_all, mape_train_linear, mape_train_pool, mape_linear_all, mape_linear, mape_pool],\n",
    "    ['MAE', mae_train_linear_all, mae_train_linear, mae_train_pool, mae_linear_all, mae_linear, mae_pool],\n",
    "    ['RMSE', rmse_train_linear_all, rmse_train_linear, rmse_train_pool, rmse_linear_all, rmse_linear, rmse_pool]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
